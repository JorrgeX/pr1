{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7024ce6",
   "metadata": {},
   "source": [
    "# Task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e98688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, sys, csv, random\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d35318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChebSum2_Clenshaw_matrix',\n",
       " 'Cheb_coeffs2',\n",
       " 'cheb',\n",
       " 'np',\n",
       " 'scipy',\n",
       " 'solve1Dcommittor']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HELPER_PATH = \"Committor1D_helpers.py\"\n",
    "\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"comm1d_helpers\", HELPER_PATH)\n",
    "if spec is None or spec.loader is None:\n",
    "    raise FileNotFoundError(f\"Could not load {HELPER_PATH}. Place it next to this notebook or update HELPER_PATH.\")\n",
    "comm = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"comm1d_helpers\"] = comm\n",
    "spec.loader.exec_module(comm)\n",
    "\n",
    "[name for name in dir(comm) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vprime_param(x, p0, p1, p2):\n",
    "    base = 4*x**3 - 4*x\n",
    "    gauss = np.exp(-((x - p1)**2) / (2 * p2**2))\n",
    "    d_bump = p0 * gauss * (-(x - p1) / (p2**2))\n",
    "    return base + d_bump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(nu=120, neval=100, N_cheb=256, seed=42, split=0.8):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    beta = 1.0\n",
    "    Nx_f = 1001\n",
    "    x_f = np.linspace(-1.0, 1.0, Nx_f)\n",
    "\n",
    "    P_list, Y_list, Q_list = [], [], []\n",
    "    for _ in range(nu):\n",
    "        p0 = rng.uniform(0.0, 5.0)\n",
    "        p1 = rng.uniform(-0.5, 0.5)\n",
    "        p2 = rng.uniform(0.25, 0.7)\n",
    "\n",
    "        f_x = Vprime_param(x_f, p0, p1, p2)\n",
    "        y = rng.uniform(-1.0, 1.0, size=(neval,))\n",
    "        qy = comm.solve1Dcommittor(N_cheb, 1.0, 0.0, f_x, x_f, beta, y)\n",
    "\n",
    "        P_list.append(np.tile(np.array([p0, p1, p2])[None, :], (neval, 1)))\n",
    "        Y_list.append(y[:, None])\n",
    "        Q_list.append(qy[:, None])\n",
    "\n",
    "    P = np.vstack(P_list).astype(np.float32)\n",
    "    Y = np.vstack(Y_list).astype(np.float32)\n",
    "    Q = np.vstack(Q_list).astype(np.float32)\n",
    "\n",
    "    samples_per_pot = neval\n",
    "    n_train_pot = int(split * nu)\n",
    "    train_idx = np.arange(0, n_train_pot * samples_per_pot)\n",
    "    test_idx  = np.arange(n_train_pot * samples_per_pot, P.shape[0])\n",
    "\n",
    "    return (P[train_idx], Y[train_idx], Q[train_idx]), (P[test_idx], Y[test_idx], Q[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd8bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (9600, 3) (9600, 1) (9600, 1)\n",
      "Test  shapes: (2400, 3) (2400, 1) (2400, 1)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for data\n",
    "nu, neval, N_cheb = 120, 100, 256\n",
    "(P_tr, Y_tr, Q_tr), (P_te, Y_te, Q_te) = make_dataset(nu=nu, neval=neval, N_cheb=N_cheb, seed=SEED, split=0.8)\n",
    "\n",
    "print(\"Train shapes:\", P_tr.shape, Y_tr.shape, Q_tr.shape)\n",
    "print(\"Test  shapes:\",  P_te.shape, Y_te.shape, Q_te.shape)\n",
    "\n",
    "# Normalize parameters (B)\n",
    "def normalize_P(P):\n",
    "    Pn = P.copy()\n",
    "    # p0 in [0,5], p1 in [-0.5,0.5], p2 in [0.25,0.7]\n",
    "    Pn[:,0] = (Pn[:,0] - 0.0) / 5.0\n",
    "    Pn[:,1] = (Pn[:,1] - (-0.5)) / 1.0\n",
    "    Pn[:,2] = (Pn[:,2] - 0.25) / 0.45\n",
    "    return Pn\n",
    "\n",
    "P_tr = normalize_P(P_tr)\n",
    "P_te = normalize_P(P_te)\n",
    "\n",
    "# save the dataset\n",
    "np.savez(\"parametric_committor_train.npz\", P=P_tr, Y=Y_tr, Q=Q_tr)\n",
    "np.savez(\"parametric_committor_test.npz\",  P=P_te, Y=Y_te, Q=Q_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6a46c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XYDataset(Dataset):\n",
    "    def __init__(self, P, Y, Q):\n",
    "        self.P = torch.from_numpy(P).float()\n",
    "        self.Y = torch.from_numpy(Y).float()\n",
    "        self.Q = torch.from_numpy(Q).float()\n",
    "    def __len__(self): return self.P.shape[0]\n",
    "    def __getitem__(self, idx): return self.P[idx], self.Y[idx], self.Q[idx]\n",
    "\n",
    "batch = 512\n",
    "tr_ds = XYDataset(P_tr, Y_tr, Q_tr)\n",
    "te_ds = XYDataset(P_te, Y_te, Q_te)\n",
    "tr_loader = DataLoader(tr_ds, batch_size=batch, shuffle=True)\n",
    "te_loader = DataLoader(te_ds, batch_size=max(1024, batch), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbfc753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden=(128,128), act=nn.Tanh):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), act()]\n",
    "            d = h\n",
    "        layers += [nn.Linear(d, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, K=3):\n",
    "        super().__init__()\n",
    "        self.K = K\n",
    "        self.pi = math.pi\n",
    "    def forward(self, y):  # y in [-1,1], shape [B,1]\n",
    "        feats = [y]\n",
    "        for k in range(1, self.K+1):\n",
    "            feats.append(torch.sin(k * self.pi * y))\n",
    "            feats.append(torch.cos(k * self.pi * y))\n",
    "        return torch.cat(feats, dim=1)  # [B, 1+2K]\n",
    "\n",
    "class DeepONetParametric(nn.Module):\n",
    "    def __init__(self, latent=64, hidden=(128,128), act=nn.Tanh, fourier_K=3):\n",
    "        super().__init__()\n",
    "        self.branch = MLP(3, latent, hidden=hidden, act=act)\n",
    "        self.ff = FourierFeatures(K=fourier_K)\n",
    "        self.trunk  = MLP(1 + 2*fourier_K, latent, hidden=hidden, act=act)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    def forward(self, p, y):\n",
    "        b = self.branch(p)\n",
    "        t = self.trunk(self.ff(y))\n",
    "        s = (b * t).sum(dim=1, keepdim=True) + self.bias\n",
    "        return torch.sigmoid(s)  # keep q in [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ba333",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def rmse(model, loader, device):\n",
    "    model.eval()\n",
    "    se, n = 0.0, 0\n",
    "    for p, y, q in loader:\n",
    "        p, y, q = p.to(device), y.to(device), q.to(device)\n",
    "        pred = model(p, y)\n",
    "        se += ((pred - q) ** 2).sum().item()\n",
    "        n  += q.numel()\n",
    "    return math.sqrt(se / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc2157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 | Train RMSE 9.8968e-02 | Test RMSE 1.0930e-01\n",
      "Epoch   10 | Train RMSE 3.7777e-02 | Test RMSE 4.5389e-02\n",
      "Epoch   20 | Train RMSE 1.6411e-02 | Test RMSE 2.2539e-02\n",
      "Epoch   30 | Train RMSE 1.3128e-02 | Test RMSE 1.9287e-02\n",
      "Epoch   40 | Train RMSE 1.2110e-02 | Test RMSE 1.7171e-02\n",
      "Epoch   50 | Train RMSE 1.1426e-02 | Test RMSE 1.5248e-02\n",
      "Epoch   60 | Train RMSE 1.2743e-02 | Test RMSE 1.6300e-02\n",
      "Epoch   70 | Train RMSE 1.2547e-02 | Test RMSE 1.5258e-02\n",
      "Epoch   80 | Train RMSE 1.0189e-02 | Test RMSE 1.3274e-02\n",
      "Epoch   90 | Train RMSE 8.3074e-03 | Test RMSE 1.1819e-02\n",
      "Epoch  100 | Train RMSE 8.4933e-03 | Test RMSE 1.2366e-02\n",
      "Epoch  110 | Train RMSE 8.1789e-03 | Test RMSE 1.1329e-02\n",
      "Epoch  120 | Train RMSE 6.6667e-03 | Test RMSE 1.0737e-02\n",
      "Epoch  130 | Train RMSE 9.8078e-03 | Test RMSE 1.2274e-02\n",
      "Epoch  140 | Train RMSE 6.6871e-03 | Test RMSE 1.0638e-02\n",
      "Epoch  150 | Train RMSE 7.9545e-03 | Test RMSE 1.0843e-02\n",
      "Epoch  160 | Train RMSE 5.5922e-03 | Test RMSE 9.0574e-03\n",
      "Epoch  170 | Train RMSE 6.2437e-03 | Test RMSE 9.1794e-03\n",
      "Epoch  180 | Train RMSE 5.2171e-03 | Test RMSE 8.7653e-03\n",
      "Epoch  190 | Train RMSE 5.0451e-03 | Test RMSE 8.0434e-03\n",
      "Epoch  200 | Train RMSE 4.9434e-03 | Test RMSE 8.4638e-03\n",
      "Epoch  210 | Train RMSE 5.6552e-03 | Test RMSE 8.4804e-03\n",
      "Epoch  220 | Train RMSE 4.6380e-03 | Test RMSE 7.6591e-03\n",
      "Epoch  230 | Train RMSE 7.3201e-03 | Test RMSE 9.6991e-03\n",
      "Epoch  240 | Train RMSE 3.9658e-03 | Test RMSE 7.0569e-03\n",
      "Epoch  250 | Train RMSE 3.8101e-03 | Test RMSE 7.6473e-03\n",
      "Epoch  260 | Train RMSE 4.5100e-03 | Test RMSE 7.2806e-03\n",
      "Epoch  270 | Train RMSE 3.9192e-03 | Test RMSE 6.6777e-03\n",
      "Epoch  280 | Train RMSE 5.1312e-03 | Test RMSE 7.8894e-03\n",
      "Epoch  290 | Train RMSE 4.0105e-03 | Test RMSE 6.7868e-03\n",
      "Epoch  300 | Train RMSE 3.8053e-03 | Test RMSE 7.2694e-03\n",
      "Restored best checkpoint with Test RMSE = 6.6777e-03\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model  = DeepONetParametric(latent=64, hidden=(128,128), fourier_K=3).to(device)\n",
    "opt    = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "epochs  = 300\n",
    "hist = []  # (epoch, train_rmse, test_rmse)\n",
    "\n",
    "best_te = float('inf')\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, epochs+1):\n",
    "    model.train()\n",
    "    for p, y, q in tr_loader:\n",
    "        p, y, q = p.to(device), y.to(device), q.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred = model(p, y)\n",
    "        data_loss = loss_fn(pred, q)\n",
    "\n",
    "        # reuse first two params (if batch>=2)\n",
    "        if p.shape[0] >= 2:\n",
    "            p_bc = p[:2]\n",
    "        else:\n",
    "            p_bc = p.mean(dim=0, keepdim=True).repeat(2,1)\n",
    "        y_bc = torch.tensor([[-1.0],[1.0]], dtype=torch.float32, device=device)\n",
    "        q_bc = model(p_bc, y_bc)\n",
    "        bc_loss = (q_bc[0,0] - 0.0)**2 + (q_bc[1,0] - 1.0)**2\n",
    "\n",
    "        loss = data_loss + 1e-2 * bc_loss \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if ep == 1 or ep % 10 == 0 or ep == epochs:\n",
    "        tr_rmse = rmse(model, tr_loader, device)\n",
    "        te_rmse = rmse(model, te_loader, device)\n",
    "        hist.append((ep, tr_rmse, te_rmse))\n",
    "        print(f\"Epoch {ep:4d} | Train RMSE {tr_rmse:.4e} | Test RMSE {te_rmse:.4e}\")\n",
    "\n",
    "        # Save best checkpoint by test RMSE\n",
    "        if te_rmse < best_te - 1e-5:\n",
    "            best_te = te_rmse\n",
    "            best_state = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "\n",
    "# Restore best\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"Restored best checkpoint with Test RMSE = {best_te:.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac08f1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_rmse</th>\n",
       "      <th>test_rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.098968</td>\n",
       "      <td>0.109299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.037777</td>\n",
       "      <td>0.045389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.016411</td>\n",
       "      <td>0.022539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.019287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>0.017171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.015248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.015258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.013274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>0.008307</td>\n",
       "      <td>0.011819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.012366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>110</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.011329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>120</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.010737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>130</td>\n",
       "      <td>0.009808</td>\n",
       "      <td>0.012274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>140</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>0.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>150</td>\n",
       "      <td>0.007954</td>\n",
       "      <td>0.010843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>160</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.009057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>170</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>0.009179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>180</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.008765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>190</td>\n",
       "      <td>0.005045</td>\n",
       "      <td>0.008043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.008464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>210</td>\n",
       "      <td>0.005655</td>\n",
       "      <td>0.008480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>220</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.007659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>230</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.009699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>240</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.007057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>250</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.007647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>260</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0.007281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>270</td>\n",
       "      <td>0.003919</td>\n",
       "      <td>0.006678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>280</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.007889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>290</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>300</td>\n",
       "      <td>0.003805</td>\n",
       "      <td>0.007269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_rmse  test_rmse\n",
       "0       1    0.098968   0.109299\n",
       "1      10    0.037777   0.045389\n",
       "2      20    0.016411   0.022539\n",
       "3      30    0.013128   0.019287\n",
       "4      40    0.012110   0.017171\n",
       "5      50    0.011426   0.015248\n",
       "6      60    0.012743   0.016300\n",
       "7      70    0.012547   0.015258\n",
       "8      80    0.010189   0.013274\n",
       "9      90    0.008307   0.011819\n",
       "10    100    0.008493   0.012366\n",
       "11    110    0.008179   0.011329\n",
       "12    120    0.006667   0.010737\n",
       "13    130    0.009808   0.012274\n",
       "14    140    0.006687   0.010638\n",
       "15    150    0.007954   0.010843\n",
       "16    160    0.005592   0.009057\n",
       "17    170    0.006244   0.009179\n",
       "18    180    0.005217   0.008765\n",
       "19    190    0.005045   0.008043\n",
       "20    200    0.004943   0.008464\n",
       "21    210    0.005655   0.008480\n",
       "22    220    0.004638   0.007659\n",
       "23    230    0.007320   0.009699\n",
       "24    240    0.003966   0.007057\n",
       "25    250    0.003810   0.007647\n",
       "26    260    0.004510   0.007281\n",
       "27    270    0.003919   0.006678\n",
       "28    280    0.005131   0.007889\n",
       "29    290    0.004011   0.006787\n",
       "30    300    0.003805   0.007269"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"deeponet_parametric.pt\")\n",
    "metrics_df = pd.DataFrame(hist, columns=[\"epoch\", \"train_rmse\", \"test_rmse\"])\n",
    "metrics_df.to_csv(\"metrics.csv\", index=False)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152bba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>q_true</th>\n",
       "      <th>q_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.00</td>\n",
       "      <td>-2.978520e-15</td>\n",
       "      <td>0.009882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.99</td>\n",
       "      <td>2.463430e-03</td>\n",
       "      <td>0.010666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.98</td>\n",
       "      <td>4.929374e-03</td>\n",
       "      <td>0.011563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.97</td>\n",
       "      <td>7.399752e-03</td>\n",
       "      <td>0.012584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.96</td>\n",
       "      <td>9.876449e-03</td>\n",
       "      <td>0.013739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y        q_true    q_pred\n",
       "0 -1.00 -2.978520e-15  0.009882\n",
       "1 -0.99  2.463430e-03  0.010666\n",
       "2 -0.98  4.929374e-03  0.011563\n",
       "3 -0.97  7.399752e-03  0.012584\n",
       "4 -0.96  9.876449e-03  0.013739"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick first test sample's parameters (already normalized)\n",
    "p0n, p1n, p2n = P_te[0, 0], P_te[0, 1], P_te[0, 2]\n",
    "\n",
    "p0 = p0n * 5.0 + 0.0\n",
    "p1 = p1n * 1.0 + (-0.5)\n",
    "p2 = p2n * 0.45 + 0.25\n",
    "\n",
    "y_line = np.linspace(-1, 1, 201).astype(np.float32)\n",
    "x_f = np.linspace(-1.0, 1.0, 1001)\n",
    "f_x = Vprime_param(x_f, float(p0), float(p1), float(p2))\n",
    "q_true = comm.solve1Dcommittor(256, 1.0, 0.0, f_x, x_f, 1.0, y_line)\n",
    "\n",
    "with torch.no_grad():\n",
    "    P_rep = torch.tensor(np.tile([p0n,p1n,p2n], (y_line.size,1)), dtype=torch.float32).to(device)\n",
    "    Y_rep = torch.tensor(y_line[:,None], dtype=torch.float32).to(device)\n",
    "    q_pred = model(P_rep, Y_rep).cpu().numpy().squeeze()\n",
    "\n",
    "pd.DataFrame({\"y\": y_line, \"q_true\": q_true, \"q_pred\": q_pred}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc75af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'DeepONet',\n",
       " 'dataset': 'parametric',\n",
       " 'train_rmse': 0.003919191968680557,\n",
       " 'test_rmse': 0.006677686448951258}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeponet_train_rmse = rmse(model, tr_loader, device)\n",
    "deeponet_test_rmse = rmse(model, te_loader, device)\n",
    "deeponet_metrics = {\n",
    "    \"model\": \"DeepONet\",\n",
    "    \"dataset\": \"parametric\",\n",
    "    \"train_rmse\": float(deeponet_train_rmse),\n",
    "    \"test_rmse\": float(deeponet_test_rmse),\n",
    "}\n",
    "with open(\"deeponet_results.json\", \"w\") as f:\n",
    "    json.dump(deeponet_metrics, f, indent=2)\n",
    "deeponet_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "da",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
